# Mitigating Bias in MRI-Based Alzheimer's Disease Classifiers through Pruning of Deep Neural Networks

## Abstract
With the increasing prevalence of Alzheimer’s disease among the elderly population, the development of machine learning models for early identification is crucial. However, it has been observed that these models may exhibit inherent biases, leading to performance disparities across protected attributes such as age and gender. In this study, we propose a model pruning method aimed at reducing bias and achieving model fairness in a pre-trained neural network designed for Alzheimer’s disease identification. Our pruning method takes into account both bias reduction and model performance. The results demonstrate that our pro- posed pruning method significantly reduces disparities between age and gender attributes compared to the baseline model. For disparity in age at- tributes, our method successfully reduces disparity across multiple met- rics, such as true positive rate (−7.3%). Similarly, for gender attribute, our approach mitigated bias in evaluation metrics, such as true nega- tive rate (−5.0%). The results also show that our method maintains or even improves the model’s performance and outperforms other methods across most evaluation metrics. These compelling findings underscore the immense potential of our approach in effectively mitigating gender and age disparities in MRI-based Alzheimer’s disease identification.

## Introduction

Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by the degeneration of nerve cells and loss of brain tissue. Research has explored the po- tential of using machine learning (ML) models on MRI data for the diagnosis of AD. Dufumier et al. [1] combined y-aware metadata and contrastive learning for various binary classification tasks, including AD classification. Zhuang et al. [2] proposed a method inspired by solving a Rubik’s Cube, specifically designed for 3D medical images. Liu et al. [3] trained a stacked autoencoder to learn hidden representations followed by a softmax output layer for classification. These stud- ies highlight the potential of ML in AD diagnosis, particularly when applied to MRI data.
While ML models have shown promise in Alzheimer’s disease (AD) diagnosis using MRI data, it is essential to address potential biases in the training data. ML models heavily rely on the training data to minimize prediction errors, but biases related to race, gender, and age can impact predictions, leading to performance disparities. In some cases, the model may even worsen these biases, making it untrustworthy.
To mitigate bias in ML models, various approaches have been proposed, including adversarial learning [4,5], model pruning [6,7], perturbation of loss functions [7], data preprocessing techniques [8,9], and the use of multi-source datasets [10]. However, simply reducing bias is not sufficient if it comes at the cost of a significant decrease in the overall performance of the model. It is important to find a balance between mitigating bias and maintaining or even improving the model’s performance.
Our work extends the pruning method proposed in [6] to address its limita- tions. The existing method employs a stopping criterion based on bias reaching 0, but we found that insufficiently large pruning may have minimal impact on testing data. Additionally, the method incorporates another stopping criterion involving the model’s performance dropping below a predetermined threshold, but it does not ensure bias mitigation before the model’s performance deterio- rates beyond the threshold. In our extension, we propose modifications to the pruning algorithm and fairness evaluation metric to enhance the method’s effec- tiveness in mitigating bias while maintaining model performance. Our proposed method aims to maintain the model’s performance while allowing for the pruning of more neurons, which directly enhances the model’s debiasing capability. We measure fairness by evaluating the disparities across the protected attributes using metrics such as accuracy, area under the receiver operating characteris- tics (AUC), precision, true positive rate (TPR), true negative rate (TNR), and equalized odds. Additionally, we conduct a comparative analysis of our results with other model debiasing methods.

## Reference

1. Dufumier, B., Gori, P., Victor, J., Grigis, A., Wessa, M., Bram- billa, P., Favre, P., Polosan, M., McDonald, C., Piguet, C.M., Duch- esnay, E.: Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI Classification, http://arxiv.org/abs/2106.08808, (2021). https://doi.org/10.48550/arXiv.2106.08808.
2. Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y., Zheng, Y.: Self- supervised Feature Learning for 3D Medical Images by Play- ing a Rubik’s Cube, http://arxiv.org/abs/1910.02241, (2019). https://doi.org/10.48550/arXiv.1910.02241.
3. Liu, S., Liu, S., Cai, W., Pujol, S., Kikinis, R., Feng, D.: Early diagno- sis of Alzheimer’s disease with deep learning. In: 2014 IEEE 11th Inter- national Symposium on Biomedical Imaging (ISBI). pp. 1015–1018 (2014). https://doi.org/10.1109/ISBI.2014.6868045.
4. Zhang, B.H., Lemoine, B., Mitchell, M.: Mitigating Unwanted Biases with Ad- versarial Learning. In: Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. pp. 335–340. ACM, New Orleans LA USA (2018). https://doi.org/10.1145/3278721.3278779.
5. Correa, R., Jeong, J.J., Patel, B., Trivedi, H., Gichoya, J.W., Banerjee, I.: Two- step adversarial debiasing with partial learning – medical image case-studies, http://arxiv.org/abs/2111.08711, (2021).
6. Marcinkevics, R., Ozkan, E., Vogt, J.E.: Debiasing Deep Chest X-Ray Classifiers using Intra- and Post-processing Methods. In: Proceedings of the 7th Machine Learning for Healthcare Conference. pp. 504–536. PMLR (2022).
7. Pfohl, S.R., Foryciarz, A., Shah, N.H.: An Empirical Characterization of Fair Ma- chine Learning For Clinical Risk Prediction. Journal of Biomedical Informatics. 113, 103621 (2021). https://doi.org/10.1016/j.jbi.2020.103621.
8. Larrazabal, A.J., Nieto, N., Peterson, V., Milone, D.H., Ferrante, E.: Gender im- balance in medical imaging datasets produces biased classifiers for computer-aided diagnosis. Proceedings of the National Academy of Sciences. 117, 12592–12594 (2020). https://doi.org/10.1073/pnas.1919012117.
9. Petersen,E.,Feragen,A.,Zemsch,M.L.daC.,Henriksen,A.,Christensen,O.E.W., Ganz, M.: Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer’s disease detection, http://arxiv.org/abs/2204.01737, (2022).
10. Seyyed-Kalantari, L., Liu, G., McDermott, M., Chen, I.Y., Ghassemi, M.: CheXclusion: Fairness gaps in deep chest X-ray classifiers. In: Biocomputing 2021. pp. 232–243. WORLD SCIENTIFIC, Kohala Coast, Hawaii, USA (2020). https://doi.org/10.1142/9789811232701_0022.
11. Hardt, M., Price, E., Srebro, N.: Equality of Opportunity in Supervised Learning, http://arxiv.org/abs/1610.02413,(2016). https://doi.org/10.48550/arXiv.1610.02413.
12. Savani, Y., White, C., Govindarajulu, N.S.: Intra-Processing Methods for Debias- ing Neural Networks. In: Advances in Neural Information Processing Systems. pp. 2798–2810. Curran Associates, Inc. (2020).
13. Lin, X., Kim, S., Joo, J.: FairGRAPE: Fairness-Aware GRAdient Pruning mEthod for Face Attribute Classification. In: Avidan, S., Brostow, G., Cissé, M., Farinella, G.M., and Hassner, T. (eds.) Computer Vision – ECCV 2022. pp. 414–432. Springer Nature Switzerland, Cham (2022). https://doi.org/10.1007/978-3-031-19778-9_24.
